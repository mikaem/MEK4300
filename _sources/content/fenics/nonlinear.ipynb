{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical solution of nonlinear equations\n",
    "\n",
    "Several derived equations in [Similarity solutions](../chapter3/similarity.ipynb#Similarity-solutions) (e.g., Eq. {eq}`eq:AxiStagnationNonNorm`) are nonlinear and no analytical solutions are known. Very few techniques are actually available for solving nonlinear equations analytically and as such we usually have to rely on numerical methods to obtain solutions for real fluid flows. Reynolds Averaged Navier-Stokes equations, that will be discussed thoroughly in chapter 6 of White {cite}`white06`, are basically Navier-Stokes equations with a nonlinear viscosity coefficient. In this section we will consider two of the most important techniques for iteratively solving nonlinear equations: Picard and Newton iterations.\n",
    "\n",
    "The general procedure for obtaining solutions to nonlinear equations is to guess an initial solution and then successively recompute new and hopefully better approximations to the solution.  This is illustrated nicely with Newton's method (also called Newton-Raphson's method). Consider a nonlinear function $f(x)$ of one variable $x$ (e.g., $f(x)=x^2-1$ or $f(x)=x \\sin(x)-1$), where one is interested in finding the roots $x$ such that $f(x)=0$. Newton's method boils down to making an initial guess $x_0$ that does not satisfy our equation (i.e., $f(x_0) \\neq 0$) and from this initial guess we successively compute better approximations to the final root:\n",
    "\n",
    "```{math}\n",
    "\\begin{aligned}\n",
    "\\mathrm{Guess }&\\, x_0, \\quad n=0 \\\\\n",
    "\\mathrm{while}\\,&\\,\\mathrm{not }\\, f(x_n) \\approx 0\\,\\, \\mathrm{do} \\\\\n",
    "&x_{n+1} = x_{n} - \\frac{f(x_{n})}{f'(x_{n})} \\\\\n",
    "&n = n + 1\n",
    "\\end{aligned}\n",
    "```\n",
    "\n",
    "That is, compute $x_1$ from $x_0$ and check if the solution is close enough to the root. If not, compute $x_2$ using $x_1$ as initial condition. Repeat until $f(x_n)\\approx 0$.\n",
    "\n",
    "When PDEs are solved numerically we obtain through discretization a system of many equations for many variables. Newton's method extends easily to systems of equations as well. Consider 2 equations with two unknowns written compactly as $F(\\overline{x})$\n",
    "\n",
    "```{math}\n",
    "  F(\\overline{x}) =\n",
    "  \\begin{cases}\n",
    "  x^2 + 2 x y &= 0, \\\\\n",
    "  x + 4 y^2  &= 0,\n",
    "\\end{cases}\n",
    "```\n",
    "\n",
    "where $\\overline{x} = (x, y)^T$. The vector $F$ has two components (the two equations) and there are two unknowns. We can compute the derivative of $F$ with respect to $\\overline{x}$\n",
    "\n",
    "```{math}\n",
    "  J_{ij} = \\frac{\\partial F_i}{\\partial x_j} =\n",
    "  \\begin{pmatrix}\n",
    "   2x + 2y & 2 x \\\\\n",
    "   1 & 8y\n",
    "  \\end{pmatrix}.\n",
    "```\n",
    "\n",
    "The derivative is often called the Jacobian. Newton's method for these two equations (or any system of equations) is simply\n",
    "\n",
    "```{math}\n",
    "  J(\\overline{x}^{k}) (\\overline{x}^{k+1} - \\overline{x}^{k}) = - F(\\overline{x}^{k}),\n",
    "```\n",
    "\n",
    "or with index notation for equation $i$\n",
    "\n",
    "```{math}\n",
    "  J_{ij}^k (x_j^{k+1} - x_j^{k}) = - F_i^k,\n",
    "```\n",
    "\n",
    "where the $k$ index signals that both $J$ and $F$ are computed using the solution at iteration step $k$. There is no summation on repeated $k$'s.\n",
    "\n",
    "A discrete finite element solution of the function $u$ can be written as\n",
    "\n",
    "```{math}\n",
    "  u(x) = \\sum_{i=0}^{N} u_i v_i(x),\n",
    "```\n",
    "\n",
    "where $v_i$ are the testfunctions. The solution has $N+1$ unknowns $u_i$, or \"degrees of freedom\", that for a linear Lagrange element are the values at the vertices of the mesh. When a PDE containing both trial- and testfunctions is assembled in FEniCS a set of $N+1$ linear equations arise for these unknowns. We will now see how nonlinear equations can be handled by FEniCS.\n",
    "\n",
    "## Nonlinear Poisson equation\n",
    "\n",
    "Consider the nonlinear Poisson equation\n",
    "\n",
    "```{math}\n",
    "  - \\nabla \\cdot \\left(q(u) \\nabla u \\right) = f(u),\n",
    "```\n",
    "\n",
    "where $q$ and $f$ may be nonlinear functions of $u$. Using testfunction $v$ and neglecting the boundary term the variational form reads\n",
    "\n",
    "```{math}\n",
    ":label: eq:NonlinPoissonVar\n",
    "  \\int_{\\Omega}  q(u) \\nabla u \\cdot \\nabla v \\mathrm{d}x = \\int_{\\Omega} f(u) v \\mathrm{d}x.\n",
    "```\n",
    "\n",
    "This is a nonlinear variational form and we need to solve it iteratively.\n",
    "\n",
    "### Newton's method\n",
    "\n",
    "Consider first Newton's method for solving the nonlinear Poisson equation. We use the notation $u^k$ for the known solution at iteration step $k$ and $u$ the unknown trialfunction. For Newton's method we write the variational form solely in terms of known functions\n",
    "\n",
    "```{math}\n",
    "F(u^k;v) =   \\int_{\\Omega}  q(u^k) \\nabla u^k \\cdot \\nabla v \\mathrm{d}x - \\int_{\\Omega} f(u^k) v \\mathrm{d}x.\n",
    "```\n",
    "\n",
    "$F(u^k;v)$ is a linear form in that it does not contain the unknown $u$, only the testfunction $v$. It is a *nonlinear* form in terms of the known `Function` $u^k$ though. The Jacobian of  $F(u^k;v)$ is computed is FEniCS as\n",
    "\n",
    "```python\n",
    "u_ = Function(V)\n",
    "u = TrialFunction(V)\n",
    "J = derivative(F, u_, u)\n",
    "```\n",
    "A complete implementation that solves the nonlinear Poisson equation on the unit interval x=[0, 1] is shown below, where the use of this `J` should be obvious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dolfin import *\n",
    "\n",
    "mesh = UnitIntervalMesh(10)\n",
    "V = FunctionSpace(mesh, 'CG', 1)\n",
    "u = TrialFunction(V)\n",
    "v = TestFunction(V)\n",
    "\n",
    "bc0 = DirichletBC(V, Constant(0), \"std::abs(x[0]) < 1e-10\")\n",
    "bc1 = DirichletBC(V, Constant(1), \"std::abs(x[0]-1) < 1e-10\")\n",
    "\n",
    "def q(u):\n",
    "    return 1+u**4\n",
    "    \n",
    "u_ = interpolate(Expression(\"x[0]\", degree=1), V)\n",
    "F = inner(grad(v), q(u_)*grad(u_))*dx\n",
    "##solve(F == 0, u_, [bc0, bc1])\n",
    "\n",
    "J = derivative(F, u_, u)\n",
    "du = Function(V)\n",
    "error = 1; k = 0\n",
    "while k < 100 and error > 1e-12:\n",
    "    A = assemble(J)\n",
    "    b = assemble(-F)\n",
    "    [bc.apply(A, b, u_.vector()) for bc in [bc0, bc1]]\n",
    "    solve(A, du.vector(), b)\n",
    "    u_.vector().axpy(1., du.vector())\n",
    "    error = norm(du.vector())\n",
    "    k += 1    \n",
    "    print(\"Iteration {} Error = {}\".format(k, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that everything below the line with `solve(F == 0, u_, [bc0, bc1])` actually can be replaced simply by using this very compact call. The part from `J = derivative(F, u_, u)` and out is included here simply to illustrate how Newton's method works in practise.\n",
    "\n",
    "### Picard iterations\n",
    "\n",
    "For Picard iterations we have to linearize the variational form in Eq. {eq}`eq:NonlinPoissonVar` ourself. Let us first linearize such that the coefficient is known:\n",
    "\n",
    "```{math}\n",
    "F(u;v) =   \\int_{\\Omega}  q(u^k) \\nabla u \\cdot \\nabla v \\mathrm{d}x - \\int_{\\Omega} f(u^k, u) v \\mathrm{d}x\n",
    "```\n",
    "\n",
    "The first term on the rhs of $F(u;v)$ is bilinear in that it contains both trial- and testfunctions $u$ and $v$. The equation is also linear in $u$, which is necessary for FEniCS to accept it. Note that the function $f$ could be linear in $u$ as well. For example, if $f(u) = u^2$, then we can linearize it like $f(u) = u \\cdot u^k$. Picard iterations are implemented as Newton up to the point where the form is created. The remaining part of the Picard code reads:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_ = interpolate(Expression(\"x[0]\", degree=1), V)\n",
    "F = inner(grad(v), q(u_)*grad(u))*dx\n",
    "k = 0\n",
    "u_1 = Function(V)\n",
    "error = 1\n",
    "while k < 100 and error > 1e-12:\n",
    "    solve(F == Constant(0)*v*dx, u_, [bc0, bc1])\n",
    "    error = errornorm(u_, u_1)\n",
    "    u_1.assign(u_)\n",
    "    k += 1\n",
    "    print(\"Iteration {} Error = {}\".format(k,  error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Function` `u_1` holds the previous solution and `u_1.assign(u_)` copies all values from the newly computed `u_` to `u_1`.\n",
    "\n",
    "Note that the Newton's method requires 5 iterations to converge, whereas Picard requires 13. This is quite typical. Newton's method is known to be very efficient when it actually finds the solution, but it often diverges if the initial guess is not close enough to the final solution.  Picard is known to approach the solution more slowly, but in return it is usually more robust in that it finds the solution from a broader range of initial conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```{bibliography} ../../references.bib\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
